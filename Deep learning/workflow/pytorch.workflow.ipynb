{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a536946",
   "metadata": {},
   "source": [
    "# Pytorch Workflow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd707663",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at c:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2700; latest registration was registered at c:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2700",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2699\u001b[39m\n\u001b[32m   2694\u001b[39m torch.backends.mps._init()\n\u001b[32m   2696\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compiler \u001b[38;5;28;01mas\u001b[39;00m compiler\n\u001b[32m-> \u001b[39m\u001b[32m2699\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01m_TritonLibrary\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m   2700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtriton\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEF\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mops_table\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Callable\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2700\u001b[39m, in \u001b[36m_TritonLibrary\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2699\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_TritonLibrary\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2700\u001b[39m     lib = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtriton\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEF\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2701\u001b[39m     ops_table: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], _Callable] = {}\n\u001b[32m   2703\u001b[39m     \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2704\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregisterOp\u001b[39m(\u001b[38;5;28mcls\u001b[39m, op_key, full_schema, op_impl, dispatch_key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\library.py:109\u001b[39m, in \u001b[36mLibrary.__init__\u001b[39m\u001b[34m(self, ns, kind, dispatch_key)\u001b[39m\n\u001b[32m    107\u001b[39m frame = traceback.extract_stack(limit=\u001b[32m2\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m    108\u001b[39m filename, lineno = frame.filename, frame.lineno\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28mself\u001b[39m.m: Optional[Any] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineno\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.ns = ns\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m._op_defs: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mRuntimeError\u001b[39m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at c:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2700; latest registration was registered at c:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2700"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check the version \n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a045ad7",
   "metadata": {},
   "source": [
    "### 1. Data (preparing and loading)\n",
    "\n",
    "Data can be almost anything ... in machine learning \n",
    "\n",
    "* Excel speadsheet \n",
    "* Images \n",
    "* Videos (youtube has lots of data ...)\n",
    "* Audio like songs or podcasts \n",
    "* DNA\n",
    "\n",
    "Machine learning is a game of two parts :\n",
    "\n",
    "1. Get data into a numerical representation\n",
    "2. Build a model to learn patterns in that numerical representation\n",
    "\n",
    "We'll use a linear regression formula to make straight line with known **parameters**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba122be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create *known* parameters\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "#create \n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10] , y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280c2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X) , len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6bc40",
   "metadata": {},
   "source": [
    "### Spilitting data into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6645ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a train/test spilt \n",
    "\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train , y_train = X[:train_split] , y[:train_split]\n",
    "X_test , y_test = X[train_split:] , y[train_split:]\n",
    "\n",
    "len(X_train) , len(y_train) , len(X_test) , len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da95a1",
   "metadata": {},
   "source": [
    "how might we better visualise pur data?\n",
    "\n",
    "this is where the data explorer's motto comes in!\n",
    "\" Visualise , visualise , visualise! \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd99b22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m plt.scatter(X_train, y_train, c=\u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m, s=\u001b[32m4\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mTrain data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.scatter(X_test, y_test, c=\u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m, s=\u001b[32m4\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mTest data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mpredictions\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      9\u001b[39m     plt.scatter(X_test, predictions, c=\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, s=\u001b[32m4\u001b[39m, label=\u001b[33m\"\u001b[39m\u001b[33mPredictions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m plt.legend(prop={\u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m : \u001b[32m14\u001b[39m})\n",
      "\u001b[31mNameError\u001b[39m: name 'predictions' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_train, y_train, c=\"b\", s=4, label=\"Train data\")\n",
    "plt.scatter(X_test, y_test, c=\"g\", s=4, label=\"Test data\")\n",
    "\n",
    "\n",
    "if(predictions is not None):\n",
    "    plt.scatter(X_test, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "plt.legend(prop={\"size\" : 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46eeb3",
   "metadata": {},
   "source": [
    "### 2. Build Model \n",
    "\n",
    "our first pytorch model!\n",
    "\n",
    "what our model does:?\n",
    "* Starts with random values (weight & bias)\n",
    "* Look at the training data and adjust the random values to better represent ( or get closer to) the ideal values ( the weight and bias) values we used to create the data \n",
    "\n",
    "How does it do so?\n",
    "\n",
    "Through two main algorithim\n",
    "* Gradient descent\n",
    "* Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350af57e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create linear regression model class\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLinearRegreessionModel\u001b[39;00m(nn.Module): \u001b[38;5;66;03m#<- almost everthing in pytorch inherits from nn.module \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2878\u001b[39m\n\u001b[32m   2874\u001b[39m \u001b[38;5;66;03m# `_import_device_backends` should be kept at the end to ensure\u001b[39;00m\n\u001b[32m   2875\u001b[39m \u001b[38;5;66;03m# all the other functions in this module that may be accessed by\u001b[39;00m\n\u001b[32m   2876\u001b[39m \u001b[38;5;66;03m# an autoloaded backend are defined\u001b[39;00m\n\u001b[32m   2877\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_device_backend_autoload_enabled():\n\u001b[32m-> \u001b[39m\u001b[32m2878\u001b[39m     \u001b[43m_import_device_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\__init__.py:2828\u001b[39m, in \u001b[36m_import_device_backends\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2826\u001b[39m     backend_extensions = entry_points().get(group_name, ())\n\u001b[32m   2827\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2828\u001b[39m     backend_extensions = \u001b[43mentry_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m backend_extension \u001b[38;5;129;01min\u001b[39;00m backend_extensions:\n\u001b[32m   2831\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2832\u001b[39m         \u001b[38;5;66;03m# Load the extension\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\importlib\\metadata\\__init__.py:1011\u001b[39m, in \u001b[36mentry_points\u001b[39m\u001b[34m(**params)\u001b[39m\n\u001b[32m   1000\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m   1001\u001b[39m \n\u001b[32m   1002\u001b[39m \u001b[33;03mPass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1006\u001b[39m \u001b[33;03m:return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1008\u001b[39m eps = itertools.chain.from_iterable(\n\u001b[32m   1009\u001b[39m     dist.entry_points \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m   1010\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEntryPoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m.select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\importlib\\metadata\\__init__.py:1009\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    999\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(**params) -> EntryPoints:\n\u001b[32m   1000\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return EntryPoint objects for all installed packages.\u001b[39;00m\n\u001b[32m   1001\u001b[39m \n\u001b[32m   1002\u001b[39m \u001b[33;03m    Pass selection parameters (group or name) to filter the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1006\u001b[39m \u001b[33;03m    :return: EntryPoints for all installed packages.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1008\u001b[39m     eps = itertools.chain.from_iterable(\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m         \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mentry_points\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dist \u001b[38;5;129;01min\u001b[39;00m _unique(distributions())\n\u001b[32m   1010\u001b[39m     )\n\u001b[32m   1011\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints(eps).select(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\importlib\\metadata\\__init__.py:496\u001b[39m, in \u001b[36mDistribution.entry_points\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    488\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mentry_points\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> EntryPoints:\n\u001b[32m    490\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[33;03m    Return EntryPoints for this distribution.\u001b[39;00m\n\u001b[32m    492\u001b[39m \n\u001b[32m    493\u001b[39m \u001b[33;03m    Custom providers may provide the ``entry_points.txt`` file\u001b[39;00m\n\u001b[32m    494\u001b[39m \u001b[33;03m    or override this property.\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EntryPoints._from_text_for(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mentry_points.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\importlib\\metadata\\__init__.py:915\u001b[39m, in \u001b[36mPathDistribution.read_text\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m | os.PathLike[\u001b[38;5;28mstr\u001b[39m]) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    908\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\n\u001b[32m    909\u001b[39m         \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m,\n\u001b[32m    910\u001b[39m         \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;167;01mPermissionError\u001b[39;00m,\n\u001b[32m    914\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\pathlib\\__init__.py:792\u001b[39m, in \u001b[36mPath.read_text\u001b[39m\u001b[34m(self, encoding, errors, newline)\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# Call io.text_encoding() here to ensure any warning is raised at an\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[38;5;66;03m# appropriate stack level.\u001b[39;00m\n\u001b[32m    791\u001b[39m encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    793\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anant\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\pathlib\\__init__.py:776\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    775\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:312\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.__init__\u001b[39m\u001b[34m(self, errors)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[32m    307\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[33;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[33;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m    byte sequences.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    313\u001b[39m         IncrementalDecoder.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[32m    314\u001b[39m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Create linear regression model class\n",
    "\n",
    "class LinearRegreessionModel(nn.Module): #<- almost everthing in pytorch inherits from nn.module \n",
    "    def __init__(self):\n",
    "         super().__init__()\n",
    "         self.weight = nn.Parameter(torch.randn( # <- start with a random weight and try to adjust it to the ideal weight \n",
    "              1,\n",
    "              requires_grad = True, # can thid be updated via gradient descent?\n",
    "              dtype=torch.float32 #<- pytorch loves the datatype torch.float32\n",
    "              ))\n",
    "         self.bias = nn.Parameter(torch.randn(\n",
    "              1, # startrs with a random bias and try to adjust it to ideal bias \n",
    "              requires_grad = True, # can this be updated via gradient descent?\n",
    "              dtype = torch.float32\n",
    "              ))\n",
    "         \n",
    "# Forward method to define the computation in the model \n",
    "    def forward(self , x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n",
    "         return self.weight * x + self.bias # this is linear regression\n",
    "\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b8118",
   "metadata": {},
   "source": [
    "### Pytorch model building essentials \n",
    "\n",
    "* Torch.nn - contains all of the building for computational graphs \n",
    "* Torch.nn.Parameter - what should our model try and learn , often a pytorch layer from torch.nn will set these for us \n",
    "* torch.nn.Module - the base class for all neural network modules , If you subclass it , you  should over write forward()\n",
    "* torch.optim -  this were the optimizers in Pytorch live , they will help with gradient descent \n",
    "* def forward() - all nn.Module subclass require you in the forward computation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9ec04",
   "metadata": {},
   "source": [
    "### Checking the contents of a Pytorch model\n",
    "\n",
    "Now we've created a model , let's see what's inside..\n",
    "So , we can check our model parameters or what's inside our model using .parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a220aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9079])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e271ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random seed \n",
    "torch.manual_seed(42)\n",
    "\n",
    "#Create a model instance of model \n",
    "model_0 = LinearRegreessionModel()\n",
    "\n",
    "#Check out the parameters \n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b5d892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List named parameters \n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafd56e",
   "metadata": {},
   "source": [
    "### Making prediction using `torch.inference_mode()`\n",
    "To check our model's predictive power , let's see how well it predicts y_test based on x_test , When we pass data through our model , its going to run it through the forward() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e44bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model_0(X_test)\n",
    "y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3554b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "    \n",
    "y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1776b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8600],\n",
       "        [0.8740],\n",
       "        [0.8880],\n",
       "        [0.9020],\n",
       "        [0.9160],\n",
       "        [0.9300],\n",
       "        [0.9440],\n",
       "        [0.9580],\n",
       "        [0.9720],\n",
       "        [0.9860]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24b919",
   "metadata": {},
   "source": [
    "##  3. Train model\n",
    "\n",
    "the whole ideas of training for a model to move from some unknown parameters (these may be random) to some known parameters or in other words from a poor representation of the data to a better representation data \n",
    "\n",
    "One way to measure how poor or how wrong your models predictions are is to use a loss function\n",
    "\n",
    "* Note: Loss function may also be called cost function or criterion in different areas . For our case , we're going to refer it to a loss function \n",
    "\n",
    "*  **Loss function** A function to measure how wrong your model predictions are  to the ideal outputs \n",
    "\n",
    "* **Optimiser** taken into the loss of a model and adjusts the model's parameter\n",
    "\n",
    "And specifically for pytorch , we need:\n",
    "\n",
    "* A Training loop\n",
    "* A Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09433d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfdfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the model parameter\n",
    "model_0.state_dict()\n",
    "#A parameter  is a value that the model sets itself()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function and optimizer \n",
    "Loss_fn = nn.L1Loss() # <- mean absolute error \n",
    "\n",
    "# Setup an optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(\n",
    "    params = model_0.parameters(),\n",
    "    lr = 0.01\n",
    ") # learning rate is the most important hyperparameter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864e664",
   "metadata": {},
   "source": [
    "### Building a Training loop (and a testing loop) in pytorch\n",
    "\n",
    "A couple of things we need in a training loops:\n",
    "0. Loop through the data \n",
    "1. Forward pass ( this involves data moving through our model's `forward()` function) to make predictions in data - also called forward propagation\n",
    "2. Calcualate the loss ( compare forward pass predictions to ground truth labels)\n",
    "3. Optimizer  zero grad\n",
    "4. Loss backward -  move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**Backpropagation**)\n",
    "5. Optimizer step - use the optimizer to adjust  our model's parameters to  try and improve the loss(**Gradient descent**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d39cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.inference_mode():\n",
    "    list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d3f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991b416",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 0. Loop through the data \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Set the model to training data \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mmodel_0\u001b[49m.train() \u001b[38;5;66;03m#train model and sets all parameters that require gradients to require gradients\u001b[39;00m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 1. Forward pass\u001b[39;00m\n\u001b[32m     11\u001b[39m     y_pred = model_0(X_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'model_0' is not defined"
     ]
    }
   ],
   "source": [
    "# An epoch is one loop through data \n",
    "# this is the hyper parameter because we've set it ourselves\n",
    "epochs = 10\n",
    "\n",
    "# 0. Loop through the data \n",
    "for epoch in range(epochs):\n",
    "    # Set the model to training data \n",
    "    model_0.train() #train model and sets all parameters that require gradients to require gradients\n",
    "    \n",
    "    # 1. Forward pass\n",
    "    y_pred = model_0(X_train)\n",
    "\n",
    "    # 2. Calculate the loss \n",
    "    loss = Loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Perform backpropagation on the loss with respect to the parameters of the model\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimiser (perfrom gradient descent)\n",
    "    optimizer.step() # by default how the optimiser changes will acculumate throught the loop \n",
    "\n",
    "\n",
    "    model_0.eval() #turns pff gradient tracking "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
